import{_ as t,c as a,a as i,o as r}from"./app-D0qTdr4z.js";const s="/Se/images/306/w0601.png",n="/Se/images/306/w0602.png",o="/Se/images/306/w0603.png",l="/Se/images/306/w0604.png",c="/Se/images/306/w0605.png",d="/Se/images/306/w0606.png",h={};function u(p,e){return r(),a("div",null,e[0]||(e[0]=[i('<ul><li>backhaul network</li><li>Backbone Network</li></ul><h1 id="chapter-6-infrastructure-for-transportation-cyber-physical-systems" tabindex="-1"><a class="header-anchor" href="#chapter-6-infrastructure-for-transportation-cyber-physical-systems"><span>Chapter 6: Infrastructure for Transportation Cyber-Physical Systems</span></a></h1><h2 id="smart-cities-infrastructure-and-transport-of-the-future" tabindex="-1"><a class="header-anchor" href="#smart-cities-infrastructure-and-transport-of-the-future"><span>SMART CITIES - INFRASTRUCTURE AND TRANSPORT OF THE FUTURE</span></a></h2><p><a href="https://www.youtube.com/watch?v=d1DndVz9dAs&amp;t=110s" target="_blank" rel="noopener noreferrer">Smart Cities - Infrastructure and Transport of the Future</a></p><h2 id="objectives" tabindex="-1"><a class="header-anchor" href="#objectives"><span>OBJECTIVES</span></a></h2><ol><li>Introduction</li><li>Networking among data infrastructure</li><li>Data collection and ingest</li><li>Data processing engines</li><li>Serving layer</li><li>Transportation Cyber-Physical Systems infrastructure as code</li><li>Future direction</li><li>Summary and conclusions</li></ol><h2 id="_1-introduction" tabindex="-1"><a class="header-anchor" href="#_1-introduction"><span>1. INTRODUCTION</span></a></h2><ul><li>To meet the complex data challenges of TCPS, standard data infrastructure must evolve to cope with the characteristics of TCPS data which can be described using ‘5Vs of big data’: (1) volume, (2) variety, (3) velocity, (4) veracity and (5) value.</li><li>A data infrastructure to accommodate these characteristics called lambda architecture (LA).</li><li>As shown in Fig. 6.2, the data infrastructure in LA is divided into four primary components: the data layer, the batch layer, the stream layer and the serving layer.</li><li>The batch layer is consisted of components that can store and process massive amount of data without a real-time service-level requirement.</li><li>Currently, one of the most popular software ecosystems that is being used in the batch layer is the Hadoop ecosystem, which includes the Hadoop Distributed File System (HDFS) for large-scale storage and the Hadoop MapReduce framework for data processing.</li><li>The stream layer does not maintain any persistent storage component. Instead, it relies on streaming data processing infrastructure that can ingest and process data in real time.</li><li>The serving layer is where users can interact with the data stored on the system using applications written in different programming languages.</li></ul><p><img src="'+s+'" alt="image-20241026234531365"></p><p>Figure 6.2 Lambda architecture for data infrastructure.</p><h2 id="_2-networking-among-data-infrastructure" tabindex="-1"><a class="header-anchor" href="#_2-networking-among-data-infrastructure"><span>2. NETWORKING AMONG DATA INFRASTRUCTURE</span></a></h2><ul><li>In TCPS, infrastructure, vehicles and people collaborate to support the application requirements of both end users and other stakeholders.</li><li>Data infrastructure, a centralised, distributed or centralised- distributed architecture, needs to communicate with data senders, data receivers and among components of the data infrastructure itself.</li><li>These communications take place either wirelessly or through wired mediums.</li><li>Data infrastructure could include one layer or multiple layers of data storage and processors, depending on the application requirements.</li><li>The United States Department of Transportation (USDOT) has supported the development of the Connected Vehicle Reference Implementation Architecture (CVRIA) as a guidance for developing connected vehicle applications and infrastructures.</li></ul><p><img src="'+n+'" alt="image-20241026234809589"></p><p>Figure 6.4 Vehicles and data infrastructure connected through different communication mediums [11].</p><h2 id="_3-data-collection-and-ingest" tabindex="-1"><a class="header-anchor" href="#_3-data-collection-and-ingest"><span>3. DATA COLLECTION AND INGEST</span></a></h2><ul><li>The first process that takes place within the TCPS data processing and decision support infrastructure is the collection of the data.</li><li>TCPS can have a wide variety of different data sources and needs to be able to quickly and efficiently store and capture all the data from these devices.</li><li>Once these data are collected and stored, it needs to be ingested and sent off to perform analytics on the data to extract the meaningful data.</li><li>This is typically done through a data brokering component that manages where the data are sent and how they are processed.</li></ul><h3 id="_3-1-transportation-cyber-physical-systems-data-source-challenges" tabindex="-1"><a class="header-anchor" href="#_3-1-transportation-cyber-physical-systems-data-source-challenges"><span>3.1 TRANSPORTATION CYBER-PHYSICAL SYSTEMS DATA SOURCE CHALLENGES</span></a></h3><ul><li>TCPS data can come from a variety of sources such as sensors and cameras that are connected to traffic lights, connected vehicles, satellites and even travellers.</li><li>Each of these sources produces different types of data that pertain to different aspects of a TCPS such as location, weather, route of travel, accident avoidance and overall infrastructure performance.</li><li>These different types of data need to be processed using different methods.</li><li>Some of these data collected require very little to zero processing, for example, the count of vehicles that passed a certain location during a certain period, whereas other collected data require significantly more processing such as a video feed from a CCTV camera.</li><li>This wide variability in the type of data and the processing power required to obtain the required insights from the data greatly impacts the type of data infrastructure utilised by TCPS.</li></ul><hr><ul><li>For those TCPS that require more processing intensive tasks, the underlying data infrastructure needs to not only be able to handle the amount of data being generated but also be able to process the same data efficiently.</li><li>The amount of data being collected by the TCPS can be on the scale of petabytes which poses an issue with the storage of such a large amount of data.</li><li>On top of the storage issue, there is the issue of accessing and processing the data.</li><li>This requires robust processing engines and vast amounts of infrastructure to be feasible.</li><li>Another unique aspect of a TCPS is the way that the data are transmitted to the collection site.</li><li>Some of the data collected by the TCPS come from sensors and other devices mounted on moving vehicles which poses a unique challenge.</li></ul><h3 id="_3-2-data-brokering-infrastructure" tabindex="-1"><a class="header-anchor" href="#_3-2-data-brokering-infrastructure"><span>3.2 DATA BROKERING INFRASTRUCTURE</span></a></h3><ul><li>With various components of the batch layer and stream layer, a TCPS data infrastructure is essentially a large-scale distributed system.</li><li>As a result, it faces the same challenges when scaling up the communication infrastructure.</li><li>These challenges include complex environments, heterogeneity in hardware and software components, dynamic and flexible deployment and high reliability, throughput and resiliency.</li><li>TCPS data infrastructure can then leverage the same solution that distributed systems have, which is to implement a message-oriented middleware (MOM).</li><li>In this case, messages are data elements being transferred from data sources to various data storage and processing components.</li><li>With MOM, data are sent from sources, called producers, to a queue, called broker.</li><li>The destination processing entities called consumers can acquire data actively by pulling from the broker or passively by having the data pushed by the broker.</li></ul><hr><p>Some advantages of having a MOM infrastructure instead of using remote procedure call among components are listed as follows:</p><ul><li>Communications between producers and consumers are asynchronous and loosely coupled.</li><li>Data losses through network of system failure are prevented due to intermediate in-memory storage on brokers.</li><li>As participants in communication patterns are loosely coupled, it is easier to scale individual components within the data infrastructure.</li><li>Decoupled communication also leads to reduction of failure propagation.</li></ul><h2 id="_4-data-processing-engines" tabindex="-1"><a class="header-anchor" href="#_4-data-processing-engines"><span>4. DATA PROCESSING ENGINES</span></a></h2><p>After the data have been collected and ingested, the next step is to perform analytics on the data to get the information required by the TCPS.</p><p>There are two general classes of processing engines that can be utilised by TCPS that we will be discussing: batch processing engines and stream processing engines.</p><p>Each class performs different analyses which provide valuable insight into the functionality of the TCPS.</p><h3 id="_4-1-batch-processing-engines-for-transportation-cyber-physical-systems" tabindex="-1"><a class="header-anchor" href="#_4-1-batch-processing-engines-for-transportation-cyber-physical-systems"><span>4.1 BATCH PROCESSING ENGINES FOR TRANSPORTATION CYBER-PHYSICAL SYSTEMS</span></a></h3><p>Fig. 6.5 provides an overview of Hadoop Distributed File System (HDFS)’ architectural design.</p><p>From a user’s perspective, visual observations of data stored in HDFS are like those of data stored in a standard Linux operating system.</p><p>In fact, many command-line data operations in HDFS use the same keywords as their Linux counterparts.</p><p>To ensure resiliency and reliability, HDFS utilises a heartbeat model in which the DataNodes must periodically contact the Name-Node to confirm their active status.</p><p>If a DataNode fails to do so, the NameNode will proactively initiate the process to replicate all blocks associated with this DataNode onto other DataNodes.</p><p><img src="'+o+'" alt="image-20241026235306196"></p><p>Figure 6.5 Architectural presentation of Hadoop Distributed File System (HDFS).</p><hr><p>In a data processing operation on HDFS, the programming codes developed for the Map phase will be executed on all individual data blocks.</p><p>The Hadoop MapReduce framework will spawn map tasks on DataNodes that physically store these blocks and effectively move computation to data.</p><p>Each map task would emit intermediate data under the form of <code>&lt;Key, Value&gt;</code> pairs.</p><p>We could think of a &lt;Key, Value&gt; pair as a data element, where Key represents a distinguishing characteristic of this data element (multiple data element can have similar distinguishing characteristics) and Value represents the actual relevant contents of this element.</p><p>These intermediate data elements are stored in memory and spilt over into local hard drives as they are generated.</p><p>After all Map tasks are completed, the Hadoop MapReduce framework aggregates and sorts all pairs based on their Keys.</p><p><img src="'+l+'" alt="image-20241026235424213"></p><p>Figure 6.6 Example Hadoop Distributed File System’ block distributions.</p><hr><p>Behind the scene, Hadoop MapReduce framework takes care of several critical technical steps.</p><p>To support parallelisation, it takes advantage of the fact that data stored on HDFS are already split and distributed across multiple DataNodes.</p><p>The Hadoop MapReduce framework and HDFS are the core components of the Hadoop ecosystem, which provide a reliable and highly scalable environment to support data processing.</p><p>However, due to the complexity in algorithmic designs (everything must be mapped to Map and Reduce) and overhead costs (Hadoop components are implemented using Java Virtual Machines), it is suitable for batch jobs on massive amount of data but not for interactive jobs on smaller data sets.</p><p>The Hadoop core components are among the top candidates for the batch layer of a data infrastructure.</p><h3 id="_4-2-stream-processing-engines" tabindex="-1"><a class="header-anchor" href="#_4-2-stream-processing-engines"><span>4.2 STREAM PROCESSING ENGINES</span></a></h3><p>The batch layer is more suitable for data processing tasks that aggregate massive amount of data, noninteractive, and do not require real time or near-real-time response rate.</p><p>Therefore, it is the responsibility of the stream layer to work on small- or medium-sized data in interactive manner to provide outputs in real time.</p><p>It should be noted that Apache Spark still utilises the MapReduce programming paradigm.</p><p>However, Apache Spark is implemented such that all data (original data, intermediate data and final results) are maintained in memory and reusable/accessible across different stages of interactive jobs.</p><p>Spark’s operations are classified into transformations or actions.</p><p>Transformations include operations that are pleasantly parallel in nature and will result in a new resilient distributed datasets (RDD) abstraction from existing RDD.</p><hr><ul><li>The real-time streaming analytic aspects of Spark is enabled by creating another data entry point called StreamingContext which is connected to the SparkContext and allows data to be continuously inserted into the Spark cluster’s RDD environment over time.</li><li>Unlike Flink, Spark does not work with actual continuous data streams but discretise these streams into streams of small, user-defined timing windows.</li><li>These are called discretized streams (DStreams).</li><li>Each timing window within a DStream is considered an RDD, and all standard Spark programming functionalities and practices are applicable on these RDD.</li><li>SparkStream has been observed to achieve twice the throughput of Storm, another streaming engine developed by Twitter.</li></ul><hr><p><img src="'+c+'" alt="image-20241026235639660"></p><p>Figure 6.7 Spark deployment inside Hadoop infrastructure. HDFS, Hadoop Distributed File System; RDD, resilient distributed datasets; HDD, hard disk drive.</p><h2 id="_5-serving-layer" tabindex="-1"><a class="header-anchor" href="#_5-serving-layer"><span>5. SERVING LAYER</span></a></h2><p>In the lambda architecture (LA), the serving layer is where end users can interact with the data and analytical results stored within the infrastructure.</p><p>This is can be done via a web-based application where a user can interact with the data via a web browser.</p><p>However, there are also other software tools and options for interacting with the data at the lower levels utilising various application programming interfaces (APIs) which can also be categorised into the serving layer.</p><p>At the batch layer, the Hadoop MapReduce framework supports execution of native Python and R codes driven by the map and reduce tasks.</p><p>With the Hadoop streaming library, which is part of the core Hadoop MapReduce, executable binaries (in this case Python and R programs) can be specified as map and reduce tasks and utilise Linux standard input and output to read data from HDFS’ data blocks.</p><p>There also exists APIs within Python and R to support more features from the Hadoop ecosystem.</p><h2 id="_6-transportation-cyber-physical-systems-infrastructure-as-code" tabindex="-1"><a class="header-anchor" href="#_6-transportation-cyber-physical-systems-infrastructure-as-code"><span>6. TRANSPORTATION CYBER-PHYSICAL SYSTEMS INFRASTRUCTURE AS CODE</span></a></h2><p>The TCPS data infrastructure required to collect, store, distribute and process the data generated by TCPS can be quite large and complex.</p><p>Not to mention that getting the resources within the infrastructure to work at maximum efficiency and effectiveness can be a daunting and time- consuming task that can require many configuration changes, architecture iterations and debugging.</p><p>The infrastructure as code (IaC) paradigm aims to change this by allowing users to create, modify and remove infrastructure through code.</p><p>IaC is an approach to using cloud era technologies to build and manage dynamic infrastructure.</p><p>It treats the infrastructure and the tools and services that manage the infrastructure itself as a software system, adapting software engineering practices to manage changes to the system in a structured safe way.</p><h3 id="_6-1-transportation-cyber-physical-systems-cloud-infrastructure-as-code" tabindex="-1"><a class="header-anchor" href="#_6-1-transportation-cyber-physical-systems-cloud-infrastructure-as-code"><span>6.1 TRANSPORTATION CYBER-PHYSICAL SYSTEMS CLOUD INFRASTRUCTURE AS CODE</span></a></h3><ul><li>Cloud computing has become increasingly popular over the past few years due in partto its flexibility.</li><li>Cloud computing allows users to scale up and scale down their infrastructure based upon the amount of demand which can be particularly useful for TCPS as there are peak times where a lot of data processing is required and other times where very little data processing is required.</li><li>However, this flexibility in scaling up and down does require some additional automation to be performed during the processes of creating, provisioning and removing the infrastructure to ensure that these actions are performed in a consistent and trackable manner.</li><li>This is where IaC can be utilized effectively and efficiently.</li><li>Many cloud computing providers have their own IaC solutions that are designed to help users to create, modify and delete their infrastructure within the cloud.</li><li>Amazon Web Services (AWS) has a service called CloudFormation that allows users to use a simple text file, written in JSON or YAML, to model and provision, in an automated and secure manner, all the resources required for the infrastructure.</li></ul><p><img src="'+d+'" alt="image-20241026235914837"></p><p>Figure 6.8 Sample CloudFormation template to launch an Amazon Web Services EC2 instance [24].</p><h3 id="_6-2-internet-of-things-infrastructure-as-code" tabindex="-1"><a class="header-anchor" href="#_6-2-internet-of-things-infrastructure-as-code"><span>6.2 INTERNET OF THINGS INFRASTRUCTURE AS CODE</span></a></h3><p>Along with the lower-level compute IaC, the cloud also allows for Internet of Things device and sensor infrastructure to be created, modified and removed through code.</p><p>This process is a little different than the compute infrastructure, as this process does not involve deploying actual resources, such as sensors, but rather refers to the ability to manage and update the infrastructure.</p><p>One such solution is Amazon Greengrass, a software solution that allows a user run a variety of tasks including messaging, data caching, sync, machine learning, and local compute securely on connected devices.</p><p>Greengrass uses familiar programming models and languages allowing users to create and test device software in the cloud first and then deploy it to the devices.</p><p>This allows for the quick code and device prototyping and better change tracking regarding the software running on the sensors and devices deployed out in the field.</p><h2 id="_7-future-direction" tabindex="-1"><a class="header-anchor" href="#_7-future-direction"><span>7. FUTURE DIRECTION</span></a></h2><ul><li>Over the next few years, the amount of data being generated by TCPS will continue to grow quickly.</li><li>This will lead to an increased need for more efficient and scalable data processing of the TCPS data.</li><li>This will require a tighter integration of the traditional data processing systems described in this chapter along with the flexibility and scalability provided by IaC.</li><li>By utilising IaC, TCPS will be able to dynamically adjust to handle an increase in the amount of data as more vehicles and other devices connect to the system.</li><li>This will keep TCPS running efficiently and effectively without the administrators of the system having to worry about the ever-changing data processing requirements.</li></ul><h2 id="_8-summary-and-conclusions" tabindex="-1"><a class="header-anchor" href="#_8-summary-and-conclusions"><span>8. SUMMARY AND CONCLUSIONS</span></a></h2><ul><li>Within TCPS the data are the most important information that is produced.</li><li>The data are what contains the information required to keep the TCPS operational and enable their functionality.</li><li>Similarity, without the data processing infrastructure, the TCPS would not be able to obtain or produce the information required to maintain usability.</li><li>As the requirements for data storage and processing change, the data infrastructure behind the TCPS will adapt with it and lead to even more efficient and effective systems.</li><li>IaC will allow TCPS to automatically adapt to changes in demand and will allow for faster iteration and debugging when updating the underlying infrastructure.</li><li>This will allow the people working on these systems to focus more on innovating and less on maintaining and managing the current systems.</li></ul>',91)]))}const f=t(h,[["render",u],["__file","Week06.html.vue"]]),g=JSON.parse('{"path":"/306/Week06.html","title":"Chapter 6: Infrastructure for Transportation Cyber-Physical Systems","lang":"zh-CN","frontmatter":{},"headers":[{"level":2,"title":"SMART CITIES - INFRASTRUCTURE AND TRANSPORT OF THE FUTURE","slug":"smart-cities-infrastructure-and-transport-of-the-future","link":"#smart-cities-infrastructure-and-transport-of-the-future","children":[]},{"level":2,"title":"OBJECTIVES","slug":"objectives","link":"#objectives","children":[]},{"level":2,"title":"1. INTRODUCTION","slug":"_1-introduction","link":"#_1-introduction","children":[]},{"level":2,"title":"2. NETWORKING AMONG DATA INFRASTRUCTURE","slug":"_2-networking-among-data-infrastructure","link":"#_2-networking-among-data-infrastructure","children":[]},{"level":2,"title":"3. DATA COLLECTION AND INGEST","slug":"_3-data-collection-and-ingest","link":"#_3-data-collection-and-ingest","children":[{"level":3,"title":"3.1 TRANSPORTATION CYBER-PHYSICAL SYSTEMS DATA SOURCE CHALLENGES","slug":"_3-1-transportation-cyber-physical-systems-data-source-challenges","link":"#_3-1-transportation-cyber-physical-systems-data-source-challenges","children":[]},{"level":3,"title":"3.2 DATA BROKERING INFRASTRUCTURE","slug":"_3-2-data-brokering-infrastructure","link":"#_3-2-data-brokering-infrastructure","children":[]}]},{"level":2,"title":"4. DATA PROCESSING ENGINES","slug":"_4-data-processing-engines","link":"#_4-data-processing-engines","children":[{"level":3,"title":"4.1 BATCH PROCESSING ENGINES FOR TRANSPORTATION CYBER-PHYSICAL SYSTEMS","slug":"_4-1-batch-processing-engines-for-transportation-cyber-physical-systems","link":"#_4-1-batch-processing-engines-for-transportation-cyber-physical-systems","children":[]},{"level":3,"title":"4.2 STREAM PROCESSING ENGINES","slug":"_4-2-stream-processing-engines","link":"#_4-2-stream-processing-engines","children":[]}]},{"level":2,"title":"5. SERVING LAYER","slug":"_5-serving-layer","link":"#_5-serving-layer","children":[]},{"level":2,"title":"6. TRANSPORTATION CYBER-PHYSICAL SYSTEMS INFRASTRUCTURE AS CODE","slug":"_6-transportation-cyber-physical-systems-infrastructure-as-code","link":"#_6-transportation-cyber-physical-systems-infrastructure-as-code","children":[{"level":3,"title":"6.1 TRANSPORTATION CYBER-PHYSICAL SYSTEMS CLOUD INFRASTRUCTURE AS CODE","slug":"_6-1-transportation-cyber-physical-systems-cloud-infrastructure-as-code","link":"#_6-1-transportation-cyber-physical-systems-cloud-infrastructure-as-code","children":[]},{"level":3,"title":"6.2 INTERNET OF THINGS INFRASTRUCTURE AS CODE","slug":"_6-2-internet-of-things-infrastructure-as-code","link":"#_6-2-internet-of-things-infrastructure-as-code","children":[]}]},{"level":2,"title":"7. FUTURE DIRECTION","slug":"_7-future-direction","link":"#_7-future-direction","children":[]},{"level":2,"title":"8. SUMMARY AND CONCLUSIONS","slug":"_8-summary-and-conclusions","link":"#_8-summary-and-conclusions","children":[]}],"git":{"updatedTime":1730153550000,"contributors":[{"name":"rhyme_yang","email":"rhyme_yang@live.cn","commits":3}]},"filePathRelative":"306/Week06.md"}');export{f as comp,g as data};
